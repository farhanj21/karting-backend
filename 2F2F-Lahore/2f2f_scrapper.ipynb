{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install selenium pandas webdriver-manager beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.select import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def scrape_racefacer(kart_id, kart_name):\n",
    "    \"\"\"\n",
    "    Scrape RaceFacer data for a specific kart type.\n",
    "    \n",
    "    Args:\n",
    "        kart_id: The value attribute of the kart option (e.g., \"1093\", \"1094\")\n",
    "        kart_name: The display name of the kart (e.g., \"RX8\", \"LR5\")\n",
    "    \"\"\"\n",
    "    # 1. Setup the Browser (Chrome)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # options.add_argument(\"--headless\")  # Uncomment this line if you don't want to see the browser window\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    url = \"https://www.racefacer.com/en/karting-tracks/pakistan/2f2fformulakarting\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Scraping {kart_name} (ID: {kart_id})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Opening {url}...\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # Allow initial load\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Select the specific kart type from the kart_id dropdown\n",
    "    print(f\"Selecting '{kart_name}' from kart dropdown...\")\n",
    "    try:\n",
    "        kart_select = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"kart_id\"))\n",
    "        )\n",
    "        \n",
    "        select = Select(kart_select)\n",
    "        select.select_by_value(kart_id)\n",
    "        print(f\"✓ Selected '{kart_name}' successfully\")\n",
    "        \n",
    "        # Wait for page to reload/update with selected kart data\n",
    "        time.sleep(5)\n",
    "        print(\"✓ Page updated with kart-specific data\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Could not select kart type: {e}\")\n",
    "        driver.quit()\n",
    "        return\n",
    "\n",
    "    # Select \"All time\" from the Period dropdown\n",
    "    print(\"Selecting 'All time' from Period dropdown...\")\n",
    "    try:\n",
    "        period_select = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"period\"))\n",
    "        )\n",
    "        \n",
    "        select = Select(period_select)\n",
    "        select.select_by_value('all')\n",
    "        print(\"✓ Selected 'All time' successfully\")\n",
    "        \n",
    "        # Wait for page to reload/update with all-time data\n",
    "        time.sleep(5)\n",
    "        print(\"✓ Page updated with all-time data\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Could not set period to 'All time': {e}\")\n",
    "        print(\"Proceeding with default period (Year)...\")\n",
    "\n",
    "    previous_row_count = 0\n",
    "\n",
    "    # 2. Loop to load all data\n",
    "    while True:\n",
    "        try:\n",
    "            # Count current loaded rows\n",
    "            rows = driver.find_elements(By.CLASS_NAME, \"row\")\n",
    "            current_row_count = len(rows)\n",
    "            \n",
    "            print(f\"Rows loaded so far: {current_row_count}\")\n",
    "\n",
    "            # Safety Check: If we clicked but the row count didn't change, stop.\n",
    "            if current_row_count == previous_row_count and current_row_count > 0:\n",
    "                print(\"No new data loaded after click. Stopping.\")\n",
    "                break\n",
    "            \n",
    "            previous_row_count = current_row_count\n",
    "\n",
    "            # Find and Click 'Load More'\n",
    "            load_more_btn = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \".load-more-button\"))\n",
    "            )\n",
    "            \n",
    "            # Scroll to button and click (using JS to avoid interception)\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", load_more_btn)\n",
    "            driver.execute_script(\"arguments[0].click();\", load_more_btn)\n",
    "\n",
    "            # Smart Wait: Wait until the number of rows actually increases\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    lambda d: len(d.find_elements(By.CLASS_NAME, \"row\")) > current_row_count\n",
    "                )\n",
    "            except:\n",
    "                print(\"Timed out waiting for new rows. Assuming end of list.\")\n",
    "                break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"No more 'Load more' buttons found or end of data reached.\")\n",
    "            break\n",
    "\n",
    "    # 3. Parse the fully loaded HTML\n",
    "    print(\"Parsing final data...\")\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    data = []\n",
    "\n",
    "    # --- Extract Podium (1st, 2nd, 3rd) ---\n",
    "    podium = soup.find('div', class_='track_podium')\n",
    "    if podium:\n",
    "        classes = ['first', 'second', 'third']\n",
    "        ranks = [1, 2, 3]\n",
    "        for cls, rank in zip(classes, ranks):\n",
    "            item = podium.find('a', class_=cls)\n",
    "            if item:\n",
    "                try:\n",
    "                    name = item.find('div', class_='name').get_text(strip=True)\n",
    "                    time_val = item.find('div', class_='time').get_text(strip=True)\n",
    "                    date = item.find('div', class_='date').get_text(strip=True)\n",
    "                    link = item.get('href')\n",
    "                    \n",
    "                    data.append({\n",
    "                        'Position': rank,\n",
    "                        'Name': name,\n",
    "                        'Date': date,\n",
    "                        'Max km/h': '',\n",
    "                        'Max G': '',\n",
    "                        'Best Time': time_val,\n",
    "                        'Profile URL': link,\n",
    "                        'Kart Type': kart_name\n",
    "                    })\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "\n",
    "    # --- Extract Table Rows (4 onwards) ---\n",
    "    rows = soup.find_all('div', class_='row')\n",
    "    for row in rows:\n",
    "        try:\n",
    "            pos_div = row.find('div', class_='position')\n",
    "            if not pos_div: continue\n",
    "            pos = pos_div.get_text(strip=True)\n",
    "\n",
    "            name_div = row.find('div', class_='name')\n",
    "            name = name_div.get_text(strip=True) if name_div else \"\"\n",
    "\n",
    "            date_div = row.find('div', class_='date')\n",
    "            date = date_div.get_text(strip=True) if date_div else \"\"\n",
    "\n",
    "            mk = row.find('div', class_='max-km-h')\n",
    "            max_km = mk.get_text(strip=True) if mk else \"\"\n",
    "\n",
    "            mg = row.find('div', class_='max-g')\n",
    "            max_g = mg.get_text(strip=True) if mg else \"\"\n",
    "\n",
    "            # Time is often inside an anchor tag\n",
    "            time_a = row.find('a', class_='time')\n",
    "            if time_a:\n",
    "                time_span = time_a.find('span')\n",
    "                best_time = time_span.get_text(strip=True) if time_span else time_a.get_text(strip=True)\n",
    "            else:\n",
    "                best_time = \"\"\n",
    "\n",
    "            name_link = row.find('a', class_='name-date')\n",
    "            link = name_link.get('href') if name_link else \"\"\n",
    "\n",
    "            data.append({\n",
    "                'Position': pos,\n",
    "                'Name': name,\n",
    "                'Date': date,\n",
    "                'Max km/h': max_km,\n",
    "                'Max G': max_g,\n",
    "                'Best Time': best_time,\n",
    "                'Profile URL': link,\n",
    "                'Kart Type': kart_name\n",
    "            })\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "    # 4. Save to CSV\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        # Clean duplicates just in case\n",
    "        df.drop_duplicates(subset=['Position', 'Name', 'Best Time'], inplace=True)\n",
    "        \n",
    "        # Create filename based on kart name\n",
    "        filename = f'data_2f2f_{kart_name.lower()}.csv'\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Success! Scraped {len(df)} rows. Saved to {filename}\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"No data found.\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define kart types with their IDs for 2F2F Formula Karting\n",
    "    kart_types = [\n",
    "        (\"1093\", \"RX8\"),\n",
    "        (\"1094\", \"LR5\")\n",
    "    ]\n",
    "    \n",
    "    # Scrape data for all kart types\n",
    "    for kart_id, kart_name in kart_types:\n",
    "        scrape_racefacer(kart_id, kart_name)\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
